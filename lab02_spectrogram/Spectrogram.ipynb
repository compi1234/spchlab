{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrogram\n",
    "\n",
    "+ ###### Author: Dirk Van Compernolle   \n",
    "+ ###### Modification History: 12/12/2023\n",
    "+ ###### Requires:  pyspch>=0.8\n",
    "\n",
    "This notebook is a wrapper around a Spectrogram GUI.\n",
    "It also has a list of suggested exercises that can be run with this GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div#notebook-container    { width: 95%; }\n",
       "    div#menubar-container     { width: 65%; }\n",
       "    div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# uncomment the pip install command to install pyspch -- it is required!\n",
    "#\n",
    "#!pip install git+https://github.com/compi1234/pyspch.git\n",
    "#\n",
    "try:\n",
    "    import pyspch\n",
    "except ModuleNotFoundError:\n",
    "    try:\n",
    "        print(\n",
    "        \"\"\"\n",
    "        To enable this notebook on platforms as Google Colab, \n",
    "        install the pyspch package and dependencies by running following code:\n",
    "\n",
    "        !pip install git+https://github.com/compi1234/pyspch.git\n",
    "        \"\"\"\n",
    "        )\n",
    "    except ModuleNotFoundError:\n",
    "        raise\n",
    "\n",
    "# Do the imports #\n",
    "##################\n",
    "#\n",
    "%matplotlib inline\n",
    "import os,sys \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, Audio, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "#   \n",
    "import pyspch.sp as Sps\n",
    "import pyspch.core as Spch\n",
    "import pyspch.display as Spd\n",
    "# make notebook cells stretch over the full screen\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Spectrogram GUI\n",
    "\n",
    "**iSpectrogram** is a GUI that lets you visualize various spectral representations including Fourier Spectrum, Mel spectrum and cepstrum or mel-cepstrum.\n",
    "The parameters of the spectral analysis can be modified in an interactive way.\n",
    "\n",
    "### Parameters to be passed when started the GUI\n",
    "The only parameters that you are likely to need are:\n",
    "- type (int)\n",
    "    + type=1:  standard spectrogram\n",
    "    + type=2:  spectrogram with a spectral slice plot in Right Hand figure; A frame slider controls its position\n",
    "- root (None or str, default(None) is equiv to \"pkg_resources_data\"):  root directory where the GUI will look for sampled data and segmentation files\n",
    "\n",
    "### GUI controls\n",
    "- frame shift (in msec): default=10.0\n",
    "- frame length (in msec): default=25.0\n",
    "- preemphasis: default=0.97 (range: 0.0 - 1.0)\n",
    "- mel spectrogram view: checkbox\n",
    "- cepstral view: checkbox  (if mel spectrogram box is checked, MFCCs are shown otherwise the cepstrum obtained from the Fourier Spectrum)\n",
    "- number of mel bands: default=80\n",
    "- number of cepstral coefficients: default=12\n",
    "- wavFile: name of waveform file (relative to root)\n",
    "- Range: start and endtime for waveform selection\n",
    "- segFile: name of segmentation file (relative to root)\n",
    "\n",
    "*KNOWN LIMITATIONS*:\n",
    "- The slider may for certain settings not perfectly align with the spectrogram\n",
    "- Interaction can be sluggish when \"sliding\" the slider, better is to \"click\" the intended location\n",
    "- When changing a text field: put your cursor at the end of the text and hit enter to signal your modification to the GUI !\n",
    "- The segmentation filename field is not cleared when updating the WavFile.  However, internally the segmenation information is cleared; so it will show bogus segmentation information in the GUI but not in the plot\n",
    "\n",
    "## Demo Materials \n",
    "\n",
    "#### Audio Files\n",
    "Suggested Files to choose from:  ( included in the demo directory of pyspch ) :\n",
    "- demo/friendly.wav       ... a 1 second speech fragment (used in figures in the course notes)\n",
    "- demo/male1.wav          ... a long sentence spoken by a male person\n",
    "- demo/female1.wav        ... a long sentence spoken by a female person\n",
    "- demo/train.wav          ... a train whistle\n",
    "- demo/timit_f1_sa1.wav   ... an example sentence from the TIMIT corpus\n",
    "\n",
    "#### Segmentations\n",
    "For the example speech files a number of segmentations are available (not all for each example). They have the same name as the .wav files, but a different extension:\n",
    "\".gra\" for grapheme or letter ,\".phn\" for phone and \".wrd\" for word   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5fd2d2dc60b4196ad88c2097627dd71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iSpectrogram(children=(Output(layout=Layout(border_bottom='solid 1px black', border_left='solid 1px black', boâ€¦"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to access data on the ESAT spchlab server, then add the argument:  root = \"https://homes.esat.kuleuven.be/~spchlab/data/\"\n",
    "Spd.iSpectrogram(type=1)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 1: Phonetic Segmentations\n",
    "\n",
    "1. setting up:\n",
    "    + Load a waveform and a phonetic (or graphemic) segmentation, e.g. \"demo/friendly.wav\" in combination with \"demo/friendly.gra\"\n",
    "    + set your audio at a comfortable loudness when you play the sentence\n",
    "    + use the default values for spectrogram analysis\n",
    "    + use the range slider to select small segments with boundaries as suggested in the segmentation; then hit the Audio button (only the selected segment will be played) \n",
    "2. focus on the first word 'friendly', evaluate the segmentations, listen and comment\n",
    "    + 'f-r-ie-n-d-l-iy'\n",
    "    + 'ie-n-d-l-iy' \n",
    "    + 'f' and 'f-r'\n",
    "    + do you hear what the segmentation suggest or are there obvious differences ?\n",
    "    + to what extent do you agree with the given segmentation, based on perception, based on time waveform and based on spectrogram ?\n",
    "    + is segmenting into phonemes possible \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2:  Spectrogram Parameters for the Sliding Window\n",
    "\n",
    "Any spectrogram or spectral slice is obtained by analyzing a long signal by cutting it in successive short overlapping frames, the so called sliding window approach.   \n",
    "This sliding window approach comes with a number of parameters, \n",
    "However, this sliding window should not be too short, not too long, not too much overlap, ....\n",
    "What is good or bad is determined by human hearing properties and key properties of speech.\n",
    "\n",
    "Select demo/male1.wav or demo/female1.wav as test file and use the range slider to limit your view to roughly 1 sec in order to see enough detail.\n",
    "\n",
    "The default parameters are shift=10msec, length=25msec, preemphasis=.97\n",
    "1. Play around with these values and observe the differences in the spectrogram\n",
    "2. Make shift and length short than the defaults (best to use a male demo example)\n",
    "    + choose as frame_length 5, 10, 20 msec\n",
    "    + choose as frame_shift 5, 10, 20 msec\n",
    "    + For the shortest values the spectrogram looks quite different: do you see in which way ?\n",
    "    + The above effect is not in line with human perception of speech - can you explain this ?\n",
    "    + Any idea why we advised you to use a male sample for this experiment ?\n",
    "3. Make frame length (much) longer than the default\n",
    "    + Increase the frame length gradually from 30, 50 .. 100 msec.\n",
    "    + Describe again what you see happening\n",
    "    + Describe also how a long frame length could be harmful to speech recognition\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
