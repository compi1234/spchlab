{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/compi1234/spchlab/blob/main/lab02_spectrogram/MelScale.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Google Colab\" title=\"Open in Google Colab\"></a>\n",
    "    \n",
    "<div>\n",
    "<img src=https://compi1234.github.io/spchlab/assets/tutorial_icon.jpg>\n",
    "</div>\n",
    "\n",
    "# The Mel Scale\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background:  Frequency Sensitivity in Auditory Perception\n",
    "\n",
    "The frequency range of the human ear spans from 20Hz to 20kHz.\n",
    "Many properties of our hearing system are easier understood in the frequency domain than in the time domain, which makes Fourier spectrograms a favorite representation of acoustic signals.\n",
    "\n",
    "However, Fourier analysis misses some important characteristics of hearing, especially the nonlinear characterisitics of frequency sensitivity:   \n",
    "- frequencies close to each interfere a lot, while frequencies far apart are quite independent   \n",
    "- the frequency range over which interference is prominent is small at low frequencies and much higher at high frequencies   \n",
    "\n",
    "Based on diverse perceptual experiments it was therefore suggested to model the human hearing system using a set of non uniform auditory (band-pass) filters.  The bandwidth of these filters is called the *critical bandwidth*.  \n",
    "\n",
    "### Auditory Filters in the cochlea\n",
    "\n",
    "Processing in the cochlea is easiest understood as an auditory filterbank. Individual auditory nerve fibers are sensitive only to a narrow frequency range centered around the *characteristic frequency* of the corresponding nerve fiber.  Both the density of these filters and their bandwidth follow the critical band characteristics (linear at low, logarithmic at high frequencies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the pip install command to install pyspch -- it is required!\n",
    "#!pip install git+https://github.com/compi1234/pyspch.git\n",
    "try:\n",
    "    import pyspch\n",
    "    print(\"pyspch was found - you are all set to continue\")\n",
    "except ModuleNotFoundError:\n",
    "    try:\n",
    "        print(\n",
    "        \"\"\"\n",
    "        WARNING: pyspch was not found !!\n",
    "        To enable this notebook on platforms as Google Colab, \n",
    "        install the pyspch package and dependencies by running following code:\n",
    "\n",
    "        !pip install git+https://github.com/compi1234/pyspch.git\n",
    "        \"\"\"\n",
    "        )\n",
    "    except ModuleNotFoundError:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams[\"figure.figsize\"] = (12,4)\n",
    "mpl.rcParams[\"savefig.dpi\"] = 100\n",
    "mpl.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "# When the SAVE_FIG flag is set, then pictures are save along the way\n",
    "SAVE_FIG = False\n",
    "import librosa\n",
    "from pyspch.sp.mel import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Modeling the Mel Scale\n",
    "\n",
    "From the above it is obvious that there is not such a thing as **THE** auditory frequency scale as different experiments lead to slightly different scales:  **MEL** scale, **BARK** scale, the **ERB** scale, **1/3th octave filterbanks**, ... \n",
    "\n",
    "Putting small differences aside, it is often sufficient to reason as follows:   \n",
    "- linear up to 1kHz with a bandwidth of 100Hz  \n",
    "- logartihmic above 1 kHz\n",
    "- resulting in 24 critical bands spanning the auditory frequency range\n",
    "\n",
    "In the sequel we will use the term **mel-scale** as a generic term, and \n",
    "in order to compare different implementations we rescale each such that frequency is mapped to a number corresponding for critical band number, in particular we always map 1000.0Hz to 10.0 mel.  (Note: this is our own way of standardizing different mappings; there is no established standard)\n",
    "\n",
    "The functions mel2hz() and hz2mel() implement a few of these mel-scale variants:\n",
    "- DM(Davis and Mermelstein): as defined in the 1980 paper in which they introduce the concept of mel cepstra, one of the oldest handy approximations\n",
    "- HTK: as used in the HTK and KALDI packages, based on a formula proposed by Gunnar Fant in 1959\n",
    "- Slaney: as used in the MATLAB Auditory Toolbox and also used as default in the librosa library.\n",
    "\n",
    "In Python packages librosa and torchaudio both the Slaney and HTK scales are implemented.\n",
    "\n",
    "All 'mel'-centered code is grouped in *mel.py* in this folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mels = np.arange(0.,30.,.5)\n",
    "freqs_sl = mel2hz(mels,scale='SLANEY')\n",
    "freqs_htk = mel2hz(mels,scale='HTK')\n",
    "freqs_dm = mel2hz(mels,scale='DM')\n",
    "\n",
    "fig1,ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(freqs_dm,mels,'--',color='g')\n",
    "ax1.plot(freqs_htk,mels,'--',color='b')\n",
    "ax1.plot(freqs_sl,mels,'--',color='r')\n",
    "\n",
    "ax1.legend(['DM','HTK','SLANEY']);\n",
    "\n",
    "ax1.grid()\n",
    "ax1.set_xlabel('Frequency (Hz)')\n",
    "ax1.set_ylabel(\"MEL\")\n",
    "ax1.tick_params(axis='x')\n",
    "ax1.set_title(\"MEL Scale Approximations (scaled for hz2mel(1000)=10)\\n by Davis-Mermelstein, HTK and Slaney \\n\");\n",
    "ax1.set_ylim([0.,35.])\n",
    "ax1.set_xlim([0,8000])\n",
    "\n",
    "ax1.scatter(1000,10,marker='o',s=75,color='k');\n",
    "if SAVE_FIG : \n",
    "    fig1.savefig(\"figures/mel_scale_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mel scale and Equivalent Bandwidth\n",
    "Another way to understand the mel scale is by thinking in terms of equivalent perceptual bandwidths; i.e. the range over which there is strong interference.\n",
    "Below 1kHz this bandwidth is estimated to be roughly 100Hz and at higher frequencies this bandwidth linearly increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_mel = 1.\n",
    "mels = np.arange(0.,30.,.2)\n",
    "freqs = mel2hz(mels)\n",
    "lows = mel2hz(mels-bw_mel/2)\n",
    "highs = mel2hz(mels+bw_mel/2)\n",
    "bw_hz = (highs-lows)\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(freqs,bw_hz)\n",
    "ax.set_title(\"Masking bandwidth\")\n",
    "ax.set_xlabel(\"Frequency (Hz)\")\n",
    "ax.set_ylabel(\"Bandwidth (Hz)\")\n",
    "ax.grid('on')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling a mel axis with 'mel' or 'Hz' ??\n",
    "Because the lack of standardization of a mel scale, we see in practice that people use 'Hz' as labels on the frequency axis and\n",
    "that the non linear behavior is obvious from the tick values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mels = np.arange(0.,31.,.1)\n",
    "freqs = mel2hz(mels)\n",
    "#\n",
    "fig,ax1 = plt.subplots()\n",
    "ax1.plot(freqs,mels,'--',color='b')\n",
    "ax1.grid()\n",
    "ax1.set_xlabel('Frequency (Hz)')\n",
    "ax1.set_ylabel(\"MEL\")\n",
    "ax1.set_title('MEL Scale  \\n The main y-axis shows the scale in mel ; The secondary axis uses Hz ');\n",
    "\n",
    "x_lim = np.asarray([0.,8000.])\n",
    "y_lim = hz2mel(x_lim)\n",
    "ax1.set_ylim(y_lim)\n",
    "ax1.set_xlim(x_lim)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "#specify y2_ticks at specific Hz locations\n",
    "y2_ticks = hz2mel([0,500,1000,2000,4000,8000]) \n",
    "### or use tick marks as on y1\n",
    "# y2_ticks = ax1.get_yticks()\n",
    "#\n",
    "y2_ticklabels = ['{:.0f}'.format(mel2hz(x)).rjust(5) for x in y2_ticks]\n",
    "\n",
    "# (matplotlib programming note) \n",
    "# you need to do the following lines in STRICT order to avoid warnings and/or plotting mistakes\n",
    "# 1. set the y_ticks, 2. set the y_ticklables, 3. set the y_lim identical to axis1\n",
    "ax2.set_yticks(y2_ticks)\n",
    "ax2.set_yticklabels(y2_ticklabels)\n",
    "ax2.set_ylim(y_lim)\n",
    "ax2.set_ylabel( 'Hz' );\n",
    "#SAVE_FIG = True\n",
    "if SAVE_FIG : \n",
    "    fig.savefig(\"figures/mel_scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_crit = np.arange(0.,31.,1)\n",
    "freq_crit = mel2hz(mel_crit)\n",
    "\n",
    "ax1.plot(freq_crit,mel_crit,'*',color='r',ms=10)\n",
    "ax1.set_title('The red stars are uniformaly spaced on the mel axis, 1 mel apart');\n",
    "display(fig)\n",
    "if SAVE_FIG : \n",
    "    fig.savefig(\"figures/mel_scale_critb1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_crit3 = np.arange(0.,31.,1/3.)\n",
    "freq_crit3 = mel2hz(mel_crit3)\n",
    "ax1.plot(freq_crit3,mel_crit3,'o',color='g',ms=4)\n",
    "ax1.set_title('The green circles are uniformly spaced on the mel axis, 1/3 mel apart');\n",
    "if SAVE_FIG : \n",
    "    fig.savefig(\"figures/mel_scale_critb3\")\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MEL FILTERBANK\n",
    "\n",
    "The primary purpose of the mel-scale in speech processing is to map of a **Fourier spectrum** to a **mel spectrum** .\n",
    "In practice we achieve this by running a Fourier Spectrum through a **mel filterbank**, where the individual channels in \n",
    "the filterbank are spaced uniformly on the mel scale and where the width of the filters is proportional to the critical bandwidth.\n",
    "\n",
    "Further Notes:\n",
    "- The range of the filters is limited to the main range of human speech, typically 50-6500 Hz\n",
    "\n",
    "In the example below we show a classical design:\n",
    "- a filterbank with 24 channels\n",
    "- filters that have a bandwidth of 1 mel\n",
    "- in practice the filters may be triangular in shape and be overlapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the design center frequencies and bandwidth of mel filterbank\n",
    "def plot_fb_concept(freqs,sr,colormap='hsv',bwscale=.5,Labels=True):\n",
    "    mels = hz2mel(freqs)\n",
    "    nb = len(freqs)-2\n",
    "    cf = range(1,nb+1)\n",
    "    low = range(0,nb)\n",
    "    high = range(2,nb+2)\n",
    "\n",
    "    fr_low= freqs[low]\n",
    "    fr_high = freqs[high]\n",
    "    fr_cf = freqs[cf]\n",
    "    mel_cf = mels[cf]\n",
    "    \n",
    "    # adjust plotted bandwidth\n",
    "    fr_low = bwscale*fr_low + (1-bwscale)*fr_cf\n",
    "    fr_high = bwscale*fr_high + (1-bwscale)*fr_cf\n",
    "    \n",
    "    fig,ax = plt.subplots()\n",
    "    colors = (mpl.colormaps[colormap]( np.linspace(0, 1, nb)))\n",
    "    #ax.scatter(fr_cf,np.arange(0,nb),marker='o',s=30,color=colors)\n",
    "    for i in range(nb):\n",
    "        plt.plot([fr_low[i],fr_high[i]],[mel_cf[i],mel_cf[i]],color=colors[i],linewidth=3)\n",
    "    ax.grid('on')\n",
    "    ax.set_xlim([0.,sr/2])\n",
    "    ylim = [0,hz2mel(sr/2)]\n",
    "    ax.set_ylim(ylim)\n",
    "    if Labels:\n",
    "        ax.set_xlabel('Frequency (Hz)')\n",
    "        ax.set_ylabel(\"MEL\" )\n",
    "        ax.set_title(\"%d channel MEL FILTERBANK \" % (nb) )\n",
    "    ax2 = ax.twinx()\n",
    "    # define y2_ticks explicitly as y_ticks on original axis may have out of domain (negative) values\n",
    "    y2_ticks = [0,500,1000,2000,4000,8000] # np.arange(0,nb,5*(1+nb//40))\n",
    "    y2_ticklabels = ['{:.0f}'.format(i).rjust(5) for i in y2_ticks] \n",
    "    \n",
    "    # (matplotlib programming note) \n",
    "    # you need to do the following lines in STRICT order to avoid warnings and/or plotting mistakes\n",
    "    # 1. set the y_ticks, 2. set the y_ticklables, 3. set the y_lim identical to axis1\n",
    "    ax2.set_yticks(hz2mel(y2_ticks))\n",
    "    ax2.set_yticklabels(y2_ticklabels)\n",
    "    ax2.set_ylim(ylim)\n",
    "    if Labels:\n",
    "        ax2.set_ylabel( 'Hz' );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  DESIGN PARAMETERS - MINIMAL NUMBER OF CHANNELS  ########\n",
    "sr = 16000         # sampling rate, typically 16 or 8 kHz\n",
    "n_mels = 80        # the number of mel filterbanks should not be less than 24 with 16kHz sampling or 20 channels with 8kHz sampling\n",
    "                   # such design has roughly filterbank widths equal to 1 mel; less channels would imply wider bands that would smear information too much\n",
    "                   # and should be no more than 64 for sr=8000, can go to 100 for sr=16000\n",
    "fmin = 50.         # lower cutoff can be set to 0Hz, but 50Hz is more common in practice is there is no useful acoustic energy below 50Hz\n",
    "fmax = 6500.       # higher cutoff for filterbank.  6500.Hz is an arbitrary value; it was chosen to make the first 20 bands fit nicely into the 4kHz range\n",
    "##########\n",
    "\n",
    "freqs,fbank = mel_filterbank(n_mels=n_mels,sr=sr,fmin=fmin,fmax=fmax) \n",
    "print(\"MEL FBANK Center Frequencies\")\n",
    "#print(freqs[1:-1],\"\\n\")\n",
    "#\n",
    "\n",
    "name = \"figures/mel_filterbank\"+str(n_mels)+\"_\"\n",
    "plot_fb_concept(freqs,sr=sr,Labels=True)\n",
    "if SAVE_FIG : plt.savefig(name+\"cf1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "plot_filterbank(freqs,sr=sr,ax=ax)\n",
    "for i in range(5,n_mels+1,5):\n",
    "    ax.text(freqs[i],1.025,str(i),ha='center')\n",
    "if SAVE_FIG : plt.savefig(name+\"fb1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MEL FILTERBANK more details\n",
    "The primary usage of the mel-scale in speech processing is to map of a **Fourier spectrum** to a **mel spectrum** , using a **mel filterbank**.\n",
    "\n",
    "Typically these filterbanks are designed such that overlap between adjacent bands is minimal.   The filtering itself is done by summing up the powers of Fourier spectral coefficients within a band, weighted by the filter shape.\n",
    "The most common design choice is to use triangular shaped filters along the mel scale with 50% overlap.\n",
    "\n",
    "Further Notes:\n",
    "- It is also well known that the data at the fringes of the frequency range is not be very reliable. At very low frequencies there may only be 50Hz hum from electrical equipment and at high frequencies the content is highly dependent on the sampling rate and the anti-aliasing filtering that was used.  Therefore it is common practice to throw away one or several of the lowest and highest bands in speech recognition systems or alternatively to limit the frequency range of the filterbank. \n",
    "- In the filterbank design routines below we use the librosa() functions for mel filterbank design.  Arguments *fmin* and *fmax* specify the range (outer edges) of the filterbank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A critically spaced mel filterbank\n",
    "\n",
    "The first filterbank that we design use a filter spacing (and bandwidth) of roughly 1 mel.\n",
    "This gives us 24 channels with a range of 0 - 6300 Hz.\n",
    "If we use a sampling rate of 8kHz then the upper 4 channels fall outside the usable frequency range, thus maintaining 20 channels.\n",
    "Also the first channel (0-100Hz) is likely to be useless for speech recognition applications as the content is too unpredictable.\n",
    "Alternatively we could set the fmin to 50 or 100Hz.\n",
    "\n",
    "The figures show \n",
    "(1) designed centerfrequencies and bandwidth   \n",
    "(2) designed filterbank (conceptual)\n",
    "(3) actual interpolation weights to apply to an FFT spectrum to compute a mel spectrum and simulate the filterbank above\n",
    "\n",
    "#### TASK: \n",
    "Design a filterbank for a sampling rate of 8kHz , using the full bandwidth and 20 channels.  Verify that this yields the same as taking the first 20 channels from the originally designed filterbank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  DESIGN PARAMETERS - MINIMAL NUMBER OF CHANNELS  ########\n",
    "sr = 16000         # sampling rate, typically 16 or 8 kHz\n",
    "n_mels = 24        # the number of mel filterbanks should not be less than 24 with 16kHz sampling or 20 channels with 8kHz sampling\n",
    "                   # such design has roughly filterbank widths equal to 1 mel; less channels would imply wider bands that would smear information too much\n",
    "                   # and should be no more than 64 for sr=8000, can go to 100 for sr=16000\n",
    "fmin = 50.         # lower cutoff can be set to 0Hz, but 50Hz is more common in practice is there is no useful acoustic energy below 50Hz\n",
    "fmax = 6500.       # higher cutoff for filterbank.  6500.Hz is an arbitrary value; it was chosen to make the first 20 bands fit nicely into the 4kHz range\n",
    "##########\n",
    "\n",
    "freqs,fbank = mel_filterbank(n_mels=n_mels,sr=sr,fmin=fmin,fmax=fmax) \n",
    "#print(\"MEL FBANK Center Frequencies\")\n",
    "#print(freqs[1:-1],\"\\n\")\n",
    "#\n",
    "\n",
    "name = \"figures/mel_filterbank\"+str(n_mels)+\"_\"\n",
    "plot_filterbank_cf_bw(freqs,sr=sr)\n",
    "if SAVE_FIG : plt.savefig(name+\"cf\")\n",
    "plt.show()\n",
    "plot_filterbank_mapping(freqs,sr=sr)\n",
    "if SAVE_FIG : plt.savefig(name+\"map\")\n",
    "plt.show()\n",
    "plot_filterbank(freqs,sr=sr)\n",
    "if SAVE_FIG : plt.savefig(name+\"filt\")\n",
    "plt.show()\n",
    "plot_filterbank_weights(fbank,sr=sr)\n",
    "if SAVE_FIG : plt.savefig(name+\"coef\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A high resolution mel filterbank\n",
    "\n",
    "A high resolution mel filterbank uses filter spacings and bandwidths that are significantly higher resolution than 1 mel.\n",
    "It seems to make little sense to go beyond the resolution of our Fourier spectrum.\n",
    "With some fair assumptions about sampling rate and FFT parameters (256 pt FFT for 8kHz sampling and 512pt FFT for 16kHz sampling) we can conclude that *80 channels* is a reasonable number of channels (upper limit) for a high resolution filterbank.\n",
    "In the design below we set fmin to 50Hz and fmax to 6500Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 16000         # sampling rate, typically 16 or 8 kHz\n",
    "n_mels = 80        # the number of mel filterbanks should not be less than 24 with 16kHz sampling or 20 channels with 8kHz sampling\n",
    "                   # such design has roughly filterbank widths equal to 1 mel; less channels would imply wider bands that would smear information too much\n",
    "                   # it should be no more than 64 for sr=8000, and can go up to 100 for sr=16000\n",
    "fmin = 50.         # lower cutoff is by default set to 50Hz as no significant speech frequencies are present below this\n",
    "fmax = 6500.       # will by default be 0.5*sampling_rate but with a cuttoff at 6.5kHz \n",
    "##########\n",
    "freqs,fbank = mel_filterbank(n_mels=n_mels,sr=sr,fmin=fmin,fmax=fmax) \n",
    "#print(\"MEL FBANK Center Frequencies\")\n",
    "#print(freqs[1:-1],\"\\n\")\n",
    "#\n",
    "\n",
    "name = \"figures/mel_filterbank\"+str(n_mels)+\"_\"\n",
    "plot_filterbank_cf_bw(freqs,sr=sr)\n",
    "if SAVE_FIG : plt.savefig(name+\"cf\")\n",
    "plt.show()\n",
    "plot_filterbank_mapping(freqs,sr=sr)\n",
    "if SAVE_FIG : plt.savefig(name+\"map\")\n",
    "plt.show()\n",
    "plot_filterbank(freqs,sr=sr)\n",
    "if SAVE_FIG : plt.savefig(name+\"filt\")\n",
    "plt.show()\n",
    "plot_filterbank_weights(fbank,sr=sr)\n",
    "if SAVE_FIG : plt.savefig(name+\"coef\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
